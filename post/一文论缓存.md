---
title: "一文论缓存"
date: 2020-05-05T16:46:52+08:00
lastmod: 2020-05-05T16:46:52+08:00
draft: false
tags: ["golang","缓存"]
categories: ["golang","缓存"]
author: "铁血执着的青春"

---

>作为后端开发的同学,缓存是必备之技能。本文将带着大家一探究竟。

## 缓存简介
缓存作为一种重要的性能提升手段,无处不在。常见的,比如操作系统,文件系统,http协议,CDN等场景使用的都非常多。使用缓存的根本原因是因为,后端的存储或者接口性能不达标,并且用户的访问带有明显的聚集效应的时候,通过使用简单的缓存手段就可以大幅度提升服务的处理性能。衡量一个缓存有效性的手段,主要就是缓存命中率,定义为缓存命中的请求和访问次数的比值。 并且使用缓存的时候,主要需要考虑两个问题:
1. 一致性问题。缓存数据和目标数据的一致性问题,如果进行缓存的更新。
2. 过期策略。缓存的淘汰算法,以及过期时间的权衡。

## 缓存的分类
单纯对一个缓存进行分类,其实是非常困难的一件事情。这里主要从三个较度进行分类:
* 实现机制
* 使用场景
* 存储类型
### 实现机制
* 本地应用缓存  
通过本地内存的方式进行缓存,比如一些常见的LRU cache实现。
* 分布式缓存 
采用比如redis,memcache等内存形的NoSQL作为集中式缓存。或者类似于CDN等内容缓存机制。

### 使用场景
* web缓存
* CDN缓存
* 文件系统缓存
* 反向代理缓存

### 存储类型
* redis 
* memcache
* squid
* varnish
* 磁盘

## 缓存的术语
### 缓存穿透
缓存穿透指的是缓存和后端存储中都没有的数据,导致大量的请求都回源到后端存储,对存储造成巨大的压力。正常思路下,我们没有从数据库中获取到数据,是不会添加缓存的。因此这种方式经常被用来对业务系统进行攻击,导致业务系统down机。

解决缓存穿透的方式主要有:
1. 业务校验。对于异常请求数据进行过滤。
2. 缓存空数据。对于一些不存在的数据,也进行缓存。但是缓存时间比有效数据稍微短一点。
### 缓存击穿
缓存击穿是指因为缓存数据过期,导致大量的请求需要回源到后端存储,造成后端压力瞬间增大。一般描述的是单个key的过期行为。

解决缓存击穿的方式主要有:
1. 缓存加锁。当需要同时回源的时候,只安排一个请求回源,其他请求等待结果返回即可。回源的请求,负责数据拉取,以及缓存更新。
2. 过期前预加载。当数据快到过期的时候,提前一段时间,去拉取数据,更新缓存。
3. 全量缓存。不采用回源的访问模式,通过定时任务的方式,将全量的db数据缓存起来,保证缓存数据的有效性。永不回源。


### 缓存雪崩
缓存雪崩是指缓存中大批量的数据到了过期时间,而且查询的数据量比较大,导致系统down机的行为。和缓存击穿不同的是,缓存击穿主要说明的是单个key的过期行为。缓存雪崩主要描述的是大量key的过期行为。

解决缓存雪崩的方式主要有:
1. 随机时间。不同的key,采用一定范围内的随机时间,保证缓存过期的时候足够分散。
2. 缓存分布式部署。按照key的类型,进行不存的缓存设计。
3. 热点数据不过期。采用离线缓存更新等方式更新缓存,热点数据不过期。

### 缓存预热
缓存预热是指系统上线之后,提前将需要缓存的数据,提前加载到缓存系统中。避免在用户请求的时候,先查询后端存储,然后在将数据进行缓存的问题。

### 缓存更新
之前阅读过coolshell的文章,主要对缓存的更新模式进行了三种不错的总结,这里直接来引用一下。
1. Cache Aside Pattern
这个是最常用的pattern了,主要逻辑如下:
* 失效：应用程序先从cache取数据,没有得到,则从数据库中取数据,然后更新缓存。
* 命中：应用程序先从cache取数据,取到之后,直接返回。
* 更新：先把数据存到数据库中,成功之后,再让缓存失效。

![
https://default-1256848756.cos.ap-guangzhou.myqcloud.com/cache%20asside%20pattern.png](
https://default-1256848756.cos.ap-guangzhou.myqcloud.com/cache%20asside%20pattern.png)

2. Read/Write Through Pattern
我们可以看到，在上面的Cache Aside套路中，我们的应用代码需要维护两个数据存储，一个是缓存（Cache），一个是数据库（Repository）。所以，应用程序比较啰嗦。而Read/Write Through套路是把更新数据库（Repository）的操作由缓存自己代理了，所以，对于应用层来说，就简单很多了。**可以理解为，应用认为后端就是一个单一的存储，而存储自己维护自己的Cache。**

* Read Through
Read Through 套路就是在查询操作中更新缓存，也就是说，当缓存失效的时候（过期或LRU换出），Cache Aside是由调用方负责把数据加载入缓存，而Read Through则用缓存服务自己来加载，从而对应用方是透明的。

* Write Through
Write Through 套路和Read Through相仿，不过是在更新数据时发生。当有数据更新的时候，如果没有命中缓存，直接更新数据库，然后返回。如果命中了缓存，则更新缓存，然后再由Cache自己更新数据库（这是一个同步操作）

![https://default-1256848756.cos.ap-guangzhou.myqcloud.com/read%20and%20write%20through%20cache.png](https://default-1256848756.cos.ap-guangzhou.myqcloud.com/read%20and%20write%20through%20cache.png)

3. Write Back Pattern
Write Back套路，一句说就是，在更新数据的时候，只更新缓存，不更新数据库，而我们的缓存会异步地批量更新数据库。这个设计的好处就是让数据的I/O操作飞快无比（因为直接操作内存嘛 ），因为异步，write backg还可以合并对同一个数据的多次操作，所以性能的提高是相当可观的。
但是，其带来的问题是，数据不是强一致性的，而且可能会丢失（我们知道Unix/Linux非正常关机会导致数据丢失，就是因为这个事）。在软件设计上，我们基本上不可能做出一个没有缺陷的设计，就像算法设计中的时间换空间，空间换时间一个道理，有时候，强一致性和高性能，高可用和高性性是有冲突的。软件设计从来都是取舍Trade-Off。
另外，Write Back实现逻辑比较复杂，因为他需要track有哪数据是被更新了的，需要刷到持久层上。操作系统的write back会在仅当这个cache需要失效的时候，才会被真正持久起来，比如，内存不够了，或是进程退出了等情况，这又叫lazy write。

![https://default-1256848756.cos.ap-guangzhou.myqcloud.com/write%20behind.png](https://default-1256848756.cos.ap-guangzhou.myqcloud.com/write%20behind.png)

## 缓存的缓存算法
### FIFO 
先进先出策略, 将数据顺序放入一个队列中, 需要缓存的数据,放置在队尾。需要淘汰的数据,从队列头部移除。

### LRU
least recently used的使用。最近最少使用算法,最近被用到得越多，不管是存还是取，就更能活下来。使用元素被访问之后,就会被移动到队列的首部。淘汰元素的时候,直接淘汰队尾的元素即可。

### LFU
Least Frequently Used的缩写，表示最近最不常用的场景。有点跟LRU类似,主要是区别是: LRU是使用一次就被提到最前面，而LFU是用一次标记一下，然后按照这个使用次数来排序。换言之，LFU有更精确的统计。也就是每次使用之后,需要动态的调整元素的位置。这种方式相对比较精准,不会因为短暂的访问,而扰乱整个存储。

## 缓存的使用模式
### 缓存的两种模式
1. 回包缓存。
这是一种非常常见的处理思路。如果缓存命中,直接返回。如果缓存不命中,那么回源后端存储,获取数据之后,更新缓存,同时返回客户端。这种情况下有两点需要考虑:
* 缓存数据种类。只缓存成功的缓存,不存在数据数据或者失败场景不缓存。
* 防止缓存击穿。可以考虑引入锁的方式,解决缓存击穿的问题,接下来会考虑讲解golang的一个防止缓存击穿的库。

2. 兜底缓存。
这种缓存模式,在后端开发中,使用得也非常多。意思是, 默认都取回源数据,回源数据获取成功,那么更新缓存,并返回客户端。回包数据获取失败,那么就获取缓存数据,返回客户端。本质上将,这是一种容灾降级的策略。

### 防止缓存击穿的库
缓存击穿的本质是,缓存失效的一瞬间,会导致大量的请求穿透到后端服务,导致后端服务出现雪崩。解决缓存击穿,可以明显降低对后端服务的请求量,但是也会导致一个rpc失败,影响一堆请求的问题。

目前golang语言使用比较多的库是: singleflight。
这个库是golang原生提供的一个库,在sync包中,使用方式可以参考如下文章:
[https://studygolang.com/articles/11063](https://studygolang.com/articles/11063)

singlefligth实现原理也比较简单,采用是waitgroup包,来实现锁等待。对于一个key的获取,只要有一个完成了,就可以直接返回了。

实现的核心数据结构有两个:
```
type call struct {
    wg  sync.WaitGroup
    val interface{}
    err error
}
```
这个结构体定了一次调用,通过wg来实现锁等待。val表示调用的返回值,err表示返回值的类型。相当于定义出了处理函数的原型:
```
func ()(val interface{},err error)
```

通过定义一个全局的group对象,来实现锁定逻辑:
```
type Group struct {
    mu sync.Mutex       // protects m
    m  map[string]*call // lazily initialized
}
```

核心的实现,是一个Group对象的Do函数,用于实现锁等待操作。
```
func (g *Group) Do(key string, fn func() (interface{}, error)) (interface{}, error) {
    g.mu.Lock()
    if g.m == nil {
        g.m = make(map[string]*call)
    }
    if c, ok := g.m[key]; ok {
        g.mu.Unlock()
        c.wg.Wait()
        return c.val, c.err
    }
    c := new(call)
    c.wg.Add(1)
    g.m[key] = c
    g.mu.Unlock()

    c.val, c.err = fn()
    c.wg.Done()

    g.mu.Lock()
    delete(g.m, key)
    g.mu.Unlock()

    return c.val, c.err
}
```

通过定义如下的代码,来实现singleflight的功能:
```
if (cacheMiss) {
    fn = func() (interface{}, error) {
        // 缓存更新逻辑
    }
    data, err = g.Do(cacheKey, fn)
}

```

## 参考文档
[缓存更新的套路](
https://coolshell.cn/articles/17416.html)
[缓存策略之LRU和LFU](
https://www.jianshu.com/p/2cf3b73914ca)